# Temporal Configuration
TEMPORAL_HOST=localhost:7233
TEMPORAL_NAMESPACE=default
TEMPORAL_TASK_QUEUE=daperl-task-queue

# Default LLM Configuration (can be overridden per-agent)
DEFAULT_LLM_PROVIDER=openai
DEFAULT_LLM_MODEL=gpt-4o
DEFAULT_LLM_TEMPERATURE=0.7
DEFAULT_LLM_MAX_TOKENS=4000

# Detection Agent LLM
# DETECTION_LLM_PROVIDER=openai
# DETECTION_LLM_MODEL=gpt-3.5-turbo
# DETECTION_LLM_TEMPERATURE=0.3
# DETECTION_LLM_MAX_TOKENS=2000

# Analysis Agent LLM
# ANALYSIS_LLM_PROVIDER=openai
# ANALYSIS_LLM_MODEL=gpt-4o
# ANALYSIS_LLM_TEMPERATURE=0.5
# ANALYSIS_LLM_MAX_TOKENS=4000

# Planning Agent LLM
# PLANNING_LLM_PROVIDER=anthropic
# PLANNING_LLM_MODEL=claude-3-5-sonnet-20241022
# PLANNING_LLM_TEMPERATURE=0.7
# PLANNING_LLM_MAX_TOKENS=8000

# Execution Agent LLM
# EXECUTION_LLM_PROVIDER=openai
# EXECUTION_LLM_MODEL=gpt-4o
# EXECUTION_LLM_TEMPERATURE=0.2
# EXECUTION_LLM_MAX_TOKENS=4000

# Reporting Agent LLM
# REPORTING_LLM_PROVIDER=openai
# REPORTING_LLM_MODEL=gpt-3.5-turbo
# REPORTING_LLM_TEMPERATURE=0.7
# REPORTING_LLM_MAX_TOKENS=3000

# Learning Agent LLM
# LEARNING_LLM_PROVIDER=openai
# LEARNING_LLM_MODEL=gpt-4o
# LEARNING_LLM_TEMPERATURE=0.5
# LEARNING_LLM_MAX_TOKENS=4000

# API Keys
OPENAI_API_KEY=sk-proj-your-key-here
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Learning Storage Configuration
LEARNING_STORAGE_TYPE=json  # Options: json, sqlite, postgresql
LEARNING_STORAGE_PATH=./data/learning.json

# MCP Server Configuration
MCP_SERVER_NAME=daperl-server
